<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>ååˆºOCR + OpenCVå‡¦ç†</title>
  <!-- OpenCV.js CDN -->
  <script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady();"></script>
  <!-- Tesseract.js -->
  <script src="https://cdn.jsdelivr.net/npm/tesseract.js@4/dist/tesseract.min.js"></script>
  <style>
    body { font-family: sans-serif; padding: 1em; }
    video, canvas, img { max-width: 100%; margin-top: 1em; border: 1px solid #ccc; }
    button { padding: 1em; font-size: 1em; margin-top: 1em; width: 100%; }
    #output { white-space: pre-wrap; margin-top: 1em; background: #f9f9f9; padding: 1em; }
  </style>
</head>
<body>

  <h2>ğŸ“· ååˆºOCR + OpenCVç”»åƒå‡¦ç†</h2>
  <video id="video" autoplay playsinline muted></video><br>
  <button onclick="captureAndRecognize()">ååˆºã‚’æ’®å½±ã—ã¦èªè­˜</button><br>
  <canvas id="canvas" style="display:none;"></canvas>
  <img id="preview" alt="æ’®å½±ç”»åƒã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"><br>
  <div id="output">èªè­˜çµæœãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™</div>

  <script>
    let cvReady = false;

    function onOpenCvReady() {
      cvReady = true;
      console.log("OpenCV.js is ready.");
    }

    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const preview = document.getElementById("preview");
    const output = document.getElementById("output");

    async function initCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: {
            facingMode: { ideal: "environment" },
            width: { ideal: 1280 },
            height: { ideal: 720 }
          },
          audio: false
        });
        video.srcObject = stream;
      } catch (err) {
        output.textContent = "ã‚«ãƒ¡ãƒ©ãŒä½¿ãˆã¾ã›ã‚“: " + err.message;
      }
    }

    initCamera();

    async function captureAndRecognize() {
      if (!cvReady) {
        output.textContent = "OpenCV.js ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¦ã„ã¾ã›ã‚“...";
        return;
      }

      // canvas ã«æç”»
      const ctx = canvas.getContext("2d");
      const targetWidth = 1280;
      const targetHeight = 720;
      canvas.width = targetWidth;
      canvas.height = targetHeight;
      ctx.drawImage(video, 0, 0, targetWidth, targetHeight);

      // OpenCVã§ç”»åƒå‡¦ç†
      const src = cv.imread(canvas);
      const dst = new cv.Mat();
      const gray = new cv.Mat();
      const blurred = new cv.Mat();
      const edged = new cv.Mat();

      // ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«åŒ–
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
      // ãƒã‚¤ã‚ºé™¤å»
      cv.GaussianBlur(gray, blurred, new cv.Size(5, 5), 0, 0, cv.BORDER_DEFAULT);
      // ã‚¨ãƒƒã‚¸æ¤œå‡º
      cv.Canny(blurred, edged, 75, 200);

      // æ¤œå‡ºã—ãŸç”»åƒã‚’ canvas ã«æç”»ï¼ˆç¢ºèªç”¨ï¼‰
      cv.imshow(canvas, edged);

      // Data URL ã«å¤‰æ›ã—ã¦ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
      const imageDataURL = canvas.toDataURL("image/png");
      preview.src = imageDataURL;

      output.textContent = "OCRå‡¦ç†ä¸­...ï¼ˆOpenCVå‡¦ç†æ¸ˆï¼‰";

      const { data: { text } } = await Tesseract.recognize(
        imageDataURL,
        'jpn',
        {
          logger: m => console.log(m),
          langPath: 'https://tessdata.projectnaptha.com/4.0.0_best/'
        }
      );

      // ãƒ¡ãƒ¢ãƒªé–‹æ”¾
      src.delete(); dst.delete(); gray.delete(); blurred.delete(); edged.delete();

      // çµæœè¡¨ç¤º
      output.textContent = "æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆ:\n" + text;
    }
  </script>

</body>
</html>
